{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Read-in data\n",
    "data=pd.read_csv(\"titanic_traning.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 2 1]\n",
      "['male' 'female' 'Male' 'Female']\n",
      "[20.     18.         nan  2.     45.     50.     44.     23.     25.\n",
      " 22.     30.     55.     32.     26.     37.     28.     41.     35.\n",
      " 27.     36.     47.      8.     29.     21.     19.     53.     31.\n",
      " 12.     39.     63.     32.5    55.5    38.     34.     42.     17.\n",
      " 33.     24.     48.     16.     49.      4.     40.      9.     15.\n",
      "  6.     51.     43.      0.9167  0.4167 11.     52.     60.     60.5\n",
      " 38.5     5.     24.5     7.     61.     14.5    20.5    14.     74.\n",
      " 36.5    57.      3.     65.     64.     54.     18.5    80.     45.5\n",
      "  0.8333 46.     59.      1.     30.5    62.     11.5    67.     58.\n",
      "  0.75   56.     28.5    34.5    70.      0.6667 71.      0.3333 13.\n",
      " 10.     76.      0.1667 26.5    70.5   ]\n",
      "[0 3 1 2 5 8 4]\n",
      "[0 2 1 3 5 6 4 9]\n",
      "[  4.    7.2  15.6   0.   27.9  29.7 106.4  10.5   nan 263.    7.7 151.6\n",
      "  23.3  57.8 135.6  22.5   7.9  26.   83.2  23.5  13.5  31.    7.8  21.\n",
      "  39.   52.6  15.   26.3  55.4  75.2  12.4  14.5   7.3  28.5  20.5  11.2\n",
      "  71.3 211.5  40.1  30.1   8.1  13.   57.    8.7  82.3  24.2 134.5  26.6\n",
      "  25.9  15.2  78.9   9.5  20.3  46.9 227.5  12.5   7.6  11.5  50.   78.\n",
      " 512.3  18.   27.8  59.4  52.   15.5  21.7  86.5  69.6   6.5  90.    8.\n",
      "  60.   32.5  27.7  62.    8.5  17.4   9.2   8.4  16.7  25.6  73.5  36.8\n",
      "  31.4   7.   12.9  49.5  19.3   6.8  23.   39.4   7.1  25.7  13.8  15.9\n",
      "   9.8  12.   65.   30.5  56.5 221.8  39.7  21.1  34.4  29.1  33.5  76.3\n",
      "   3.2  35.   27.4  77.3 262.4  42.5 120.    9.6  89.1  81.9  56.9  29.\n",
      "  41.6  31.7  30.7  31.3  91.1  39.6  32.3   9.   33.   30.   15.8  53.1\n",
      "  34.  164.9  55.   79.2  16.1  15.7   9.4  79.7  24.   58.   20.2  14.1\n",
      "  42.4  51.5  25.5  61.2  69.3  20.6 108.9  12.7 136.8  22.   78.3  51.9\n",
      "  27.    9.3  37.   75.3  35.5  11.1  26.4  22.4 133.7 113.3  50.5  76.7\n",
      "  13.9 110.9  93.5  45.5  19.5   6.9 211.3  71.   14.4  47.1  31.5  15.1\n",
      "  82.2  66.6   7.5  34.7  83.5  18.8  55.9  61.4  17.8   6.4  63.4   8.2\n",
      " 247.5  10.7  12.3  12.2  14.   16. ]\n",
      "['C' 'S' 'Q' 'Queenstown']\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "## Take a look at missing and inconsistency values:\n",
    "print(data['pclass'].unique())\n",
    "print(data['sex'].unique())    # inconsistency\n",
    "print(data['age'].unique())    # missing values\n",
    "print(data['sibsp'].unique())\n",
    "print(data['parch'].unique())\n",
    "print(data['fare'].unique())     # missing values\n",
    "print(data['embarked'].unique())  # inconsistency\n",
    "print(data['survived'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing value of age\n",
    "pd.isnull(data[\"age\"])\n",
    "c1=sum(pd.isnull(data[\"age\"]))\n",
    "c1p=\"{0:.2%}\".format(c1/916)\n",
    "#missing value of fare\n",
    "pd.isnull(data[\"fare\"])\n",
    "c2=sum(pd.isnull(data[\"fare\"]))\n",
    "c2p=\"{0:.2%}\".format(c2/916)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inconsistent value of sex\n",
    "x1=np.sum(data[\"sex\"]=='Male')\n",
    "x2=np.sum(data[\"sex\"]=='Female')\n",
    "x3=x1+x2 \n",
    "x3p=\"{0:.2%}\".format(x3/916) \n",
    "\n",
    "#inconsistent value of embarked\n",
    "data[\"embarked\"]=='Queenstown'\n",
    "x4=np.sum(data[\"embarked\"]=='Queenstown')\n",
    "x4p=\"{0:.2%}\".format(x4/916) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features MV %ofMV IV %ofIV\n",
      "pclass   0.0 0.0 0.0 0.0\n",
      "sex      0.0 0.0 4 0.44%\n",
      "age      188 20.52% 0.0 0.0\n",
      "sibsp    0.0 0.0 0.0 0.0\n",
      "parch    0.0 0.0 0.0 0.0\n",
      "fare     9 0.98% 0.0 0.0\n",
      "embarked 0.0 0.0 3 0.33%\n",
      "survived 0.0 0.0 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "#generate a table of missing value and inconsistent value\n",
    "print('Features','MV','%ofMV','IV','%ofIV')\n",
    "print('pclass  ',0.00,0.00,0.00,0.00)\n",
    "print('sex     ',0.00,0.00,x3,x3p)\n",
    "print('age     ',c1,c1p,0.00,0.00)\n",
    "print('sibsp   ',0.00,0.00,0.00,0.00)\n",
    "print('parch   ',0.00,0.00,0.00,0.00)\n",
    "print('fare    ',c2,c2p,0.00,0.00)\n",
    "print('embarked',0.00,0.00,x4,x4p)\n",
    "print('survived',0.00,0.00,0.00,0.00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID  pclass     sex  age  sibsp  parch   fare    embarked  survived\n",
      "2      3       2    male  NaN      0      0   15.6           C         0\n",
      "3      4       2    male  NaN      0      0    0.0           S         0\n",
      "11    12       3  female  NaN      0      0    7.7           Q         1\n",
      "13    14       3  female  NaN      2      0   23.3           Q         1\n",
      "18    19       1    male  NaN      0      0   26.0           S         0\n",
      "21    22       3    male  NaN      1      2   23.5           S         0\n",
      "37    38       3  female  NaN      0      0    7.8           Q         1\n",
      "41    42       2  female  NaN      0      0   12.4           Q         1\n",
      "43    44       3    male  NaN      0      0    7.3           S         0\n",
      "63    64       3    male  NaN      0      0    7.8           Q         0\n",
      "76    77       3    male  NaN      0      0    8.1           S         0\n",
      "79    80       3    male  NaN      1      1   15.2           C         1\n",
      "85    86       3    male  NaN      1      0   14.5           C         0\n",
      "95    96       3    male  NaN      0      0    7.6           S         0\n",
      "100  101       3    male  NaN      0      0    7.8           Q         0\n",
      "101  102       3    male  NaN      0      0    7.9           S         1\n",
      "107  108       3    male  NaN      0      0    7.2           C         0\n",
      "110  111       3  female  NaN      1      0   15.5           Q         1\n",
      "112  113       3    male  NaN      0      0    7.8           Q         1\n",
      "116  117       3    male  NaN      2      0   21.7           C         0\n",
      "118  119       3    male  NaN      8      2   69.6           S         0\n",
      "126  127       3    male  NaN      0      0    7.6           S         0\n",
      "132  133       3  female  NaN      0      2   15.2           C         1\n",
      "134  135       3  female  NaN      1      0   15.5           Q         1\n",
      "145  146       3    male  NaN      2      0   21.7           C         0\n",
      "146  147       3  female  NaN      8      2   69.6           S         0\n",
      "158  159       3    male  NaN      0      0    7.8           Q         0\n",
      "162  163       3    male  NaN      0      0    8.1           S         0\n",
      "169  170       3  Female  NaN      0      0    8.1           S         0\n",
      "179  180       3  female  NaN      0      2    7.8           Q         0\n",
      "..   ...     ...     ...  ...    ...    ...    ...         ...       ...\n",
      "767  768       3  female  NaN      3      1   25.5           S         0\n",
      "770  771       1    male  NaN      0      0   52.0           S         0\n",
      "774  775       3    male  NaN      0      0   56.5           S         1\n",
      "775  776       1    male  NaN      0      0    0.0           S         0\n",
      "782  783       1    male  NaN      0      0   26.6           S         0\n",
      "785  786       3    male  NaN      0      0    7.9           C         0\n",
      "790  791       3    male  NaN      0      0    7.3           S         0\n",
      "792  793       3    male  NaN      0      0    7.2           C         0\n",
      "796  797       1  female  NaN      1      0  133.7           S         1\n",
      "803  804       3  female  NaN      0      0    7.8           Q         0\n",
      "808  809       3    male  NaN      1      1   14.5           S         0\n",
      "810  811       3    male  NaN      0      0    7.8           Q         0\n",
      "811  812       1    male  NaN      0      0   25.9           S         0\n",
      "814  815       3    male  NaN      0      0    7.9           S         0\n",
      "824  825       3    male  NaN      0      0    8.1           S         0\n",
      "829  830       3    male  NaN      0      0    7.7  Queenstown         0\n",
      "837  838       3    male  NaN      0      0    8.5           Q         0\n",
      "838  839       3    male  NaN      0      0    7.2           C         1\n",
      "841  842       3    male  NaN      0      0    7.9           C         0\n",
      "849  850       3  female  NaN      0      0    7.9           Q         1\n",
      "857  858       3    male  NaN      0      0    7.8           Q         1\n",
      "868  869       3    male  NaN      0      0    7.7           Q         0\n",
      "870  871       1    male  NaN      0      0   30.5           S         1\n",
      "871  872       1    male  NaN      0      0   27.7           C         0\n",
      "874  875       3  female  NaN      0      0    7.8           Q         0\n",
      "877  878       3    male  NaN      0      0    7.9           S         0\n",
      "879  880       2    male  NaN      0      0   10.7           Q         0\n",
      "890  891       1  female  NaN      0      0   31.7           S         1\n",
      "892  893       3    male  NaN      1      0    6.4           C         0\n",
      "912  913       3    male  NaN      0      0    7.8           Q         0\n",
      "\n",
      "[188 rows x 9 columns]\n",
      "      ID  pclass     sex   age  sibsp  parch  fare embarked  survived\n",
      "8      9       2    male  44.0      1      0   NaN        S         0\n",
      "27    28       1    male  41.0      1      0   NaN        S         0\n",
      "62    63       3    male  34.0      1      1   NaN        S         0\n",
      "81    82       1  female  31.0      0      0   NaN        C         1\n",
      "88    89       1  female  40.0      0      0   NaN        S         1\n",
      "89    90       3    male  25.0      0      0   NaN        C         0\n",
      "135  136       3  female   9.0      4      2   NaN        S         0\n",
      "165  166       3    male  60.5      0      0   NaN        S         0\n",
      "908  909       1  female  30.0      0      0   NaN        C         1\n",
      "      ID  pclass     sex   age  sibsp  parch  fare embarked  survived\n",
      "5      6       1    Male  45.0      0      0  29.7        C         1\n",
      "160  161       3  Female  24.0      0      2  16.7        S         1\n",
      "169  170       3  Female   NaN      0      0   8.1        S         0\n",
      "756  757       3    Male  27.0      0      0   7.8        S         1\n",
      "      ID  pclass     sex   age  sibsp  parch  fare    embarked  survived\n",
      "17    18       3    male  26.0      0      0   7.9  Queenstown         0\n",
      "123  124       3  female  15.0      0      0   8.0  Queenstown         1\n",
      "829  830       3    male   NaN      0      0   7.7  Queenstown         0\n"
     ]
    }
   ],
   "source": [
    "#List/Display all the records with missing value(s) and/or inconsistent value(s).\n",
    "print(data[data['age'].isnull()])\n",
    "print(data[data['fare'].isnull()])\n",
    "\n",
    "print(data[data['sex'].isin(['Male','Female'])])\n",
    "print(data[data.embarked =='Queenstown'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handle the missing values \n",
    "Newdata = pd.read_csv(\"titanic_traning.csv\")\n",
    "changeforage = pd.DataFrame(data.age)  # work on the missing values of age\n",
    "CFA = changeforage.fillna(data.mean())\n",
    "Newdata.age = CFA\n",
    "\n",
    "changeforfare = pd.DataFrame(data.fare)  # work on the missing values of fare\n",
    "CFF = changeforfare.fillna(data.mean())\n",
    "Newdata.fare = CFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correct the data inconsistency issue\n",
    "changeforsex = pd.DataFrame(data.sex)  # work on the inconsistency of sex\n",
    "CFS = changeforsex.replace({'sex': {'Male':'male', 'Female':'female'}})\n",
    "Newdata.sex = CFS\n",
    "\n",
    "changeforemb = pd.DataFrame(data.embarked)  # work on the inconsistency of emb\n",
    "CFE = changeforemb.replace({'embarked': {'Queenstown':'Q'}})\n",
    "Newdata.embarked = CFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the clean data in a csv file\n",
    "Newdata.to_csv('NewData.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
